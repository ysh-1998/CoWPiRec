# SASRec
n_layers: 2
n_heads: 2
hidden_size: 768
inner_size: 256
hidden_dropout_prob: 0.5
attn_dropout_prob: 0.5
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.02
loss_type: 'CE'
# CoWPiRec
max_len: 128
model_name: "bert-base-uncased"
lambda: 1e-3
train_stage: inductive_ft
temperature: 0.07
MAX_ITEM_LIST_LENGTH: 10
